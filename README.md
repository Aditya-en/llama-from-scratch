# An implementation of Llama 3.2 architecture and inference
This code was tested on a laptop with gtx 1650 (4gb vram)
